from schemaforge.parsers.generic_sql import GenericSQLParser

from schemaforge.models import Table, CustomObject, Schema, Column
from schemaforge.parsers.utils import normalize_sql
import sqlparse
from sqlparse.sql import Statement, Token
from sqlparse.tokens import Keyword, DML, DDL, Name

class DB2Parser(GenericSQLParser):
    def parse(self, sql_content):
        self.schema = Schema()
        sql_content = self._strip_comments(sql_content)
        parsed = sqlparse.parse(sql_content)
        
        for statement in parsed:
            if statement.get_type() in ('CREATE', 'CREATE OR REPLACE'):
                self._process_create(statement)
            elif statement.get_type() == 'UNKNOWN':
                first_token = statement.token_first()
                if first_token and first_token.match(DDL, 'CREATE'):
                    self._process_create(statement)
                    
        return self.schema

    def _process_create(self, statement):
        tokens = [t for t in statement.tokens if not t.is_whitespace]
        
        obj_type = None
        obj_name = None
        
        for i, token in enumerate(tokens):
            val = token.value.upper()
            
            if val == 'TABLE':
                self._process_db2_table(statement)
                return
                
            if val == 'ALIAS':
                obj_type = 'ALIAS'
                if i + 1 < len(tokens):
                    # ALIAS FOR ...
                    # CREATE ALIAS name FOR target
                    # Name is at i+1
                    obj_name = tokens[i+1].value
                break
                
        if obj_type == 'ALIAS' and obj_name:
             self.schema.custom_objects.append(CustomObject(
                obj_type='ALIAS',
                name=obj_name,
                properties={'raw_sql': normalize_sql(str(statement))}
            ))

    def _process_db2_table(self, statement):
        # Use generic logic for basic structure
        # But we need to extract DB2 specific properties
        
        # 1. Extract Name and Columns using generic logic (we can reuse parts or reimplement)
        # Reusing generic _process_create_table is hard because it's monolithic.
        # Better to reimplement tailored for DB2 or call super and then enrich.
        
        # Let's try to parse manually to capture IDENTITY and TABLESPACE
        tokens = [t for t in statement.tokens if not t.is_whitespace]
        
        table_name = None
        for i, token in enumerate(tokens):
            if token.value.upper() == 'TABLE':
                if i + 1 < len(tokens):
                    table_name = self._clean_name(tokens[i+1].value)
                break
                
        if not table_name:
            return
            
        table = Table(name=table_name)
        
        # Columns
        for token in statement.tokens:
            if isinstance(token, sqlparse.sql.Parenthesis):
                self._parse_columns_and_constraints(token, table)
                break
                
        # Post-process columns for IDENTITY
        # Generic parser might miss "GENERATED ALWAYS AS IDENTITY" as it's complex
        # We might need to refine column parsing.
        # For now, let's assume generic parser gets the column name/type, 
        # but we need to check the raw definition for IDENTITY.
        
        # Tablespace: IN "tablespace_name"
        stmt_str = str(statement).upper()
        import re
        match_ts = re.search(r'\sIN\s+([a-zA-Z0-9_"]+)', stmt_str)
        if match_ts:
            table.tablespace = self._clean_name(match_ts.group(1))
            
        # Partitioning: PARTITION BY ...
        match_part = re.search(r'PARTITION\s+BY\s+(.*?)(?:$|;)', stmt_str, re.IGNORECASE | re.DOTALL)
        if match_part:
            table.partition_by = match_part.group(1).strip()
            
        self.schema.tables.append(table)

    def _parse_column_def(self, token):
        # Override to handle IDENTITY
        col = super()._parse_column_def(token)
        if col:
            # Check for IDENTITY in the raw token
            raw = str(token).upper()
            if 'GENERATED ALWAYS AS IDENTITY' in raw or 'GENERATED BY DEFAULT AS IDENTITY' in raw:
                col.is_identity = True
        return col
