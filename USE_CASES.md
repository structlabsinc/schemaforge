# SchemaForge Enterprise Use Cases

This document details three real-world scenarios demonstrating SchemaForge's capabilities in high-compliance environments. For each use case, we provide the context, input examples, CLI command, and the exact output generated by the tool.

---

## 1. Finance: Audit Compliance (DB2 z/OS)

**Context:**
A banking ledger system requires a perfect audit trail of all transactions. The organization is migrating from a standard table to a **System-Period Temporal Table** to meet regulatory requirements, while strictly adhering to legacy mainframe storage parameters (`STOGROUP`, `PRIQTY`).

### Input State (Simplified)

**Source (`v1.sql`)**: Standard table.
```sql
CREATE TABLE "general_ledger" (
    "gl_id" BIGINT GENERATED ALWAYS AS IDENTITY,
    ...
    "description" VARCHAR(200)
) IN DATABASE "fin_db"."ts_gl" USING STOGROUP "sg_fin" PRIQTY 1000;
```

**Target (`v2.sql`)**: Temporal table with history linkage.
```sql
CREATE TABLE "general_ledger" (
    ...
    "description" VARCHAR(500), -- Column expanded
    "sys_start" TIMESTAMP(12) NOT NULL GENERATED ALWAYS AS ROW BEGIN,
    "sys_end" TIMESTAMP(12) NOT NULL GENERATED ALWAYS AS ROW END,
    "trans_id" TIMESTAMP(12) GENERATED ALWAYS AS TRANSACTION START ID,
    PERIOD FOR SYSTEM_TIME ("sys_start", "sys_end")
) ... PRIQTY 2000; -- Storage increased

CREATE TABLE "general_ledger_hist" ...; -- History table created
ALTER TABLE "general_ledger" ADD VERSIONING USE HISTORY TABLE "general_ledger_hist";
```

### Execution

```bash
sf compare --source examples/finance_compliance/v1.sql \
           --target examples/finance_compliance/v2.sql \
           --dialect db2 \
           --plan
```

### Expected Output (Execution Plan)

```text
Execution Plan:
  + Create Table: general_ledger_hist
    + Column: gl_id (BIGINT)
    + Column: account_number (CHAR(20))
    + Column: transaction_date (DATE)
    + Column: amount (NUMERIC(19,4))
    + Column: currency (CHAR(3))
    + Column: description (VARCHAR(500))
    + Column: sys_start (TIMESTAMP(12))
    + Column: sys_end (TIMESTAMP(12))
    + Column: trans_id (TIMESTAMP(12))
  ~ Modify Table: general_ledger
    ~ Property Change: Priqty: 1000 -> 2000
    + Add Column: sys_start (TIMESTAMP(12))
    + Add Column: trans_id (TIMESTAMP(12))
    ~ Modify Column: description
      ~ Type: VARCHAR(200) -> VARCHAR(500)
```

### Generated Migration SQL

```sql
-- Migration Script for db2
ALTER TABLE "GENERAL_LEDGER" ADD VERSIONING USE HISTORY TABLE "GENERAL_LEDGER_HIST";
CREATE TABLE "general_ledger_hist" (
  "gl_id" BIGINT NOT NULL,
  "account_number" CHAR(20) NOT NULL,
  "transaction_date" DATE NOT NULL,
  "amount" DECIMAL(19, 4) NOT NULL,
  "currency" CHAR(3) NOT NULL,
  "description" VARCHAR(500),
  "sys_start" TIMESTAMP(12) NOT NULL,
  "sys_end" TIMESTAMP(12) NOT NULL,
  "trans_id" TIMESTAMP(12) NOT NULL
) IN DATABASE "fin_db"."ts_gl_hist" USING STOGROUP "sg_hist" PRIQTY 1000 SECQTY 500;
ALTER TABLE "general_ledger" ADD COLUMN "sys_start" TIMESTAMP(12) NOT NULL GENERATED ALWAYS AS ROW BEGIN;
ALTER TABLE "general_ledger" ADD COLUMN "sys_end" TIMESTAMP(12) NOT NULL GENERATED ALWAYS AS ROW END;
ALTER TABLE "general_ledger" ADD COLUMN "trans_id" TIMESTAMP(12) GENERATED ALWAYS AS TRANSACTION START ID;
ALTER TABLE "general_ledger" ADD COLUMN "period" FOR SYSTEM_TIME ("SYS_START", "SYS_END");
ALTER TABLE "general_ledger" ALTER COLUMN "description" SET DATA TYPE VARCHAR(500);
```

---

## 2. Healthcare: HIPAA Security (PostgreSQL)

**Context:**
A healthcare provider is upgrading their patient database to enforce **Row Level Security (RLS)**. This ensures that doctors can only view records associated with their organization, a critical HIPAA compliance measure. PII (SSN) is also being migrated to an encrypted format.

### Input State

**Source (`v1.sql`)**: Open access.
```sql
CREATE TABLE patients (
    patient_id UUID PRIMARY KEY,
    ssn TEXT, -- Unprotected
    ...
);
```

**Target (`v2.sql`)**: Secured with RLS.
```sql
CREATE TABLE patients (
    ...
    ssn_encrypted BYTEA,
    org_id UUID NOT NULL
);
ALTER TABLE patients ENABLE ROW LEVEL SECURITY;

CREATE POLICY "doctor_view_policy" ON patients ... USING (org_id = current_setting('app.current_org_id')::UUID);
```

### Execution

```bash
sf compare --source examples/healthcare_hipaa/v1.sql \
           --target examples/healthcare_hipaa/v2.sql \
           --dialect postgres \
           --plan
```

### Expected Output (Execution Plan)

```text
Execution Plan:
  ~ Modify Table: patients
    ~ Property Change: Row Security: False -> True
    + Add Column: ssn_encrypted (BYTEA)
    + Add Column: org_id (UUID)
    - Drop Column: ssn
  ~ Modify Table: medical_records
    + Add Column: is_sensitive (BOOLEAN)
    ~ Modify Column: notes
      ~ Comment: None -> PHI: Contains detailed clinical notes
  + Create Policy: admin_all_policy
```

### Generated Migration SQL

```sql
-- Migration Script for postgres
ALTER TABLE PATIENTS ENABLE ROW LEVEL SECURITY;
CREATE POLICY "ADMIN_ALL_POLICY" ON PATIENTS TO "ROLE_ADMIN" USING (TRUE) WITH CHECK (TRUE);
ALTER TABLE "patients" ADD COLUMN "ssn_encrypted" BYTEA;
ALTER TABLE "patients" ADD COLUMN "org_id" UUID NOT NULL;
ALTER TABLE "patients" DROP COLUMN "ssn";
ALTER TABLE "medical_records" ADD COLUMN "is_sensitive" BOOLEAN DEFAULT FALSE;
```

---

## 3. SaaS: Multi-Tenant Scale (MySQL)

**Context:**
A high-growth e-commerce platform needs to partition its massive `orders` table by year to maintain performance. It also introduces a `region_id` to the `users` table to prepare for future sharding.

### Input State

**Source (`v1.sql`)**: Single huge table.
```sql
CREATE TABLE orders (
    order_id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    ...
) ENGINE=InnoDB;
```

**Target (`v2.sql`)**: Partitioned by Range.
```sql
CREATE TABLE orders (
    order_id BIGINT UNSIGNED AUTO_INCREMENT,
    order_date DATETIME NOT NULL,
    PRIMARY KEY (order_id, order_date)
) ENGINE=InnoDB
PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    ...
);
```

### Execution

```bash
sf compare --source examples/saas_multitenant/v1.sql \
           --target examples/saas_multitenant/v2.sql \
           --dialect mysql \
           --plan
```

### Expected Output (Execution Plan)

```text
Execution Plan:
  ~ Modify Table: USERS
    + Add Column: region_id (INT)
    + Add Index: FT_USER_EMAIL (EMAIL)
  ~ Modify Table: ORDERS
    ~ Property Change: Partition: None -> RANGE (YEAR(ORDER_DATE)) (
    PARTITION P2023 VALUES LESS THAN (2024),
    PARTITION P2024 VALUES LESS THAN (2025),
    PARTITION P2025 VALUES LESS THAN (2026),
    PARTITION P_FUTURE VALUES LESS THAN MAXVALUE
)
    + Add Column: order_date (DATETIME)
```

### Generated Migration SQL

```sql
-- Migration Script for mysql
CREATE FULLTEXT INDEX FT_USER_EMAIL ON USERS(EMAIL);
ALTER TABLE `users` ADD COLUMN `region_id` INT NOT NULL DEFAULT 1;
CREATE INDEX `idx_region` ON `users` (`region_id`);
ALTER TABLE `orders` ADD COLUMN `order_date` DATETIME NOT NULL;
ALTER TABLE `orders` MODIFY COLUMN `order_id` BIGINT UNSIGNED AUTO_INCREMENT;
ALTER TABLE `orders` MODIFY COLUMN `user_id` BIGINT UNSIGNED NOT NULL;
ALTER TABLE `orders` MODIFY COLUMN `total_amount` DECIMAL(10, 2) NOT NULL;
ALTER TABLE `orders` MODIFY COLUMN `status` ENUM('PENDING', 'PAID', 'SHIPPED') DEFAULT 'PENDING';
```

---

## 4. Analytics: Modern Pipelines (Snowflake)

**Context:**
A data engineering team is modernizing their batch ETL process. They need to replace complex Airflow DAGs with Snowflake's native **Dynamic Tables** for declarative pipeline management. They also need to optimize query performance for large datasets using **Clustering**.

### Input State

**Source (`v1.sql`)**: Raw ingestion table.
```sql
CREATE TABLE raw_events (
    event_id VARCHAR(36),
    event_timestamp TIMESTAMP_NTZ,
    event_type VARCHAR(50),
    user_id VARCHAR(36),
    payload VARIANT,
    processed_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
);
```

**Target (`v2.sql`)**: Optimized storage + Dynamic Table pipeline.
```sql
CREATE TABLE raw_events (
    ...
) CLUSTER BY (TO_DATE(event_timestamp));

ALTER TABLE raw_events SET TAG cost_center = 'analytics_prod';

CREATE DYNAMIC TABLE daily_metrics
    TARGET_LAG = '1 hour'
    WAREHOUSE = 'compute_wh'
AS
SELECT
    TO_DATE(event_timestamp) AS metric_date,
    event_type,
    COUNT(*) AS event_count
FROM raw_events
GROUP BY 1, 2;
```

### Execution

```bash
sf compare --source examples/analytics_snowflake/v1.sql \
           --target examples/analytics_snowflake/v2.sql \
           --dialect snowflake \
           --plan
```

### Expected Output

```text
Execution Plan:
  ~ Modify Table: RAW_EVENTS
    ~ Property Change: Cluster By: None -> TO_DATE(EVENT_TIMESTAMP)
    ~ Governance: Set Tag COST_CENTER = 'analytics_prod'
  + Create Dynamic Table: DAILY_METRICS
    + Lag: 1 hour
    + Warehouse: compute_wh
```

### Generated Migration SQL

```sql
-- Migration Script for snowflake
ALTER TABLE "RAW_EVENTS" CLUSTER BY (TO_DATE(EVENT_TIMESTAMP));
ALTER TABLE "RAW_EVENTS" SET TAG COST_CENTER = 'analytics_prod';
CREATE DYNAMIC TABLE "DAILY_METRICS" TARGET_LAG = '1 hour' WAREHOUSE = 'compute_wh' AS SELECT TO_DATE(event_timestamp) AS metric_date, event_type, COUNT(*) AS event_count FROM raw_events GROUP BY 1, 2;
```

---

## 5. Logistics: High Throughput (Oracle)

**Context:**
A global shipping company needs a tracking database that can handle thousands of status updates per second. To achieve this, they are migrating to an **Index Organized Table (IOT)** to minimize disk I/O for primary key lookups and implementing **Hash Partitioning** to distribute write load evenly.

### Input State

**Source (`v1.sql`)**: Standard Heap Table.
```sql
CREATE TABLE shipment_tracking (
    tracking_id VARCHAR2(50) NOT NULL,
    status_code VARCHAR2(10),
    location_id NUMBER(10),
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT pk_shipment PRIMARY KEY (tracking_id)
);
```

**Target (`v2.sql`)**: IOT with Partitioning.
```sql
CREATE TABLE shipment_tracking (
    ...
    CONSTRAINT pk_shipment PRIMARY KEY (tracking_id)
) ORGANIZATION INDEX
PARTITION BY HASH (tracking_id) PARTITIONS 16;
```

### Execution

```bash
sf compare --source examples/logistics_oracle/v1.sql \
           --target examples/logistics_oracle/v2.sql \
           --dialect oracle \
           --plan
```

### Expected Output

```text
Execution Plan:
  ~ Modify Table: SHIPMENT_TRACKING
    ~ Property Change: Organization: HEAP -> INDEX
    ~ Property Change: Partition: None -> HASH (TRACKING_ID) PARTITIONS 16
```

### Generated Migration SQL

```sql
-- Migration Script for oracle
ALTER TABLE "shipment_tracking" MOVING TABLESPACE "TS_DATA" ORGANIZATION INDEX;
ALTER TABLE "shipment_tracking" MODIFY PARTITION BY HASH ("tracking_id") PARTITIONS 16;
```

---

## 6. Corporate: Corporate Identity (MSSQL)

**Context:**
An enterprise HR system is refactoring its employee directory. They are replacing inefficient recursive self-joins with the **HierarchyID** data type for optimized tree traversal. They are also moving legacy configuration data into typed **XML** columns for validation.

### Input State

**Source (`v1.sql`)**: Flat table with self-join.
```sql
CREATE TABLE Employees (
    EmployeeID INT PRIMARY KEY,
    ManagerID INT, -- Requires recursive CTEs to query
    FullName NVARCHAR(100),
    Title NVARCHAR(50)
);

CREATE TABLE Config (
    KeyName VARCHAR(50) PRIMARY KEY,
    ValueString VARCHAR(MAX) -- Unvalidated text
);
```

**Target (`v2.sql`)**: Hierarchical + XML.
```sql
CREATE TABLE Employees (
    OrgNode HIERARCHYID NOT NULL,
    OrgLevel AS OrgNode.GetLevel(),
    EmployeeID INT UNIQUE,
    FullName NVARCHAR(100),
    Title NVARCHAR(50)
);
CREATE CLUSTERED INDEX IX_Employees_OrgNode ON Employees(OrgNode);

CREATE TABLE Config (
    KeyName VARCHAR(50) PRIMARY KEY,
    ValueXML XML -- Typed storage
);
```

### Execution

```bash
sf compare --source examples/corporate_mssql/v1.sql \
           --target examples/corporate_mssql/v2.sql \
           --dialect mssql \
           --plan
```

### Expected Output

```text
Execution Plan:
  ~ Modify Table: Config
    ~ Modify Column: ValueString -> ValueXML
      ~ Type: VARCHAR(MAX) -> XML
  ~ Modify Table: Employees
    + Add Column: OrgNode (HIERARCHYID)
    + Add Column: OrgLevel (AS OrgNode.GetLevel())
    - Drop Column: ManagerID
    + Create Index: IX_Employees_OrgNode (CLUSTERED)
```

### Generated Migration SQL

```sql
-- Migration Script for mssql
ALTER TABLE [employees] ADD [orgnode] HIERARCHYID NOT NULL;
ALTER TABLE [employees] ADD [orglevel] AS ([orgnode].[getlevel]());
ALTER TABLE [employees] DROP COLUMN [managerid];
ALTER TABLE [employees] ALTER COLUMN [employeeid] INT NULL;
CREATE UNIQUE INDEX [uk_employees_employeeid] ON [employees]([employeeid]);
CREATE CLUSTERED INDEX [ix_employees_orgnode] ON [employees]([OrgNode]);
ALTER TABLE [config] ADD [valuexml] XML;
ALTER TABLE [config] DROP COLUMN [valuestring];
```
